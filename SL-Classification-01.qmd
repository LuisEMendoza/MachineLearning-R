---
title: "Aprendizaje Supervisado en R: Clasificación"
format: html
editor: visual
---

## Vecinos cercanos (kNN) {#quarto}

Se trata de algortimos que utilizan la cercanía en cuanto a ciertos valores de las variables consideradas importantes para realizar una clasificación.

### Reconociendo señales viales con kNN {#reconociendo-señales-viales-con-knn}

Después de haber tenido un humano detrás del volante por varios viajes, es hora de que el coche autónomo intente probarse a sí mismo.

Al comienzo del viaje, la cámara obtiene la imagen de una señal vial de alto. Esta se;al ha sido codificada siguiendo parámetros que pueden ser leidos por el algoritmo y se almacenan en un conjunto de datos llamado `next_sign`. Apliquemos un clasificador kNN para ayudar al coche a reconocer la señal.

Carguemos tanto la librería `class` como el set de datos `signs`, el cual contiene las observaciones de entrenamiento. Lo primero lo realizamos de la manera habitual:

```{r}
library(class)
```

Lo segundo lo haremos de una manera diferente, ya que nuestros datos se encuentran en un archivo de texto independiente de RStudio. Utilizaremos `read.csv()` para leer el contenido del archivo que contiene nuestro set de datos.

```{r}
signs <- read.csv("Datasets/signs.csv")
```

Guardaremos la lectura a una variable `signs`, que nos representará en los sucesivo al conjunto de datos. Ahora crearemos un vector de etiquetas, al cual le asignaremos el contenido de la columna `sign_type` contenida en el conjunto de datos `signs`. Recordemos que la selección de una columna se consigue con el símbolo `$`, indicando el set original y en seguida la columna de interés:

```{r}
sign_types <- signs$sign_type
```

Ahora cargaremos los datos que representan la imagen tomada que queremos clasificar:

```{r}
next_sign <- read.csv("Datasets/next_sign.csv")
```

Es momento de realizar la clasificación de la nueva imagen con la función `knn()`. Configuraremos sus argumentos de la siguiente manera.

-   `train` se refiere a los datos de entrenamiento o de ejemplo, y en este caso será igual al *data frame* `signs` pero retirando la columna de las etiquetas (recordemos que esa la usamos para el vector de etiquetas `sign_types`).

-   El argumento `test` se refiere a los datos que se desean clasificar. Utilizaremos los correspondientes al *data frame* `next_sign`.

-   El último argumento a utilizar será `cl`, al cual le alimentaremos el vector de etiquetas `sign_types`.

```{r}
knn(train = signs[, -1], test = next_sign, cl = sign_types)
```

El resultado arrojado nos indica que efectivamente, es una señal de Alto. Luego nos muestra los posibles resultados a esta cuestión.

### Explorando los datos de las señales {#explorando-los-datos-de-las-señales}

Hemos conseguido enseñarle a la máquina a reconocer una señal de alto. Sin embargo, debemos conocer qué información le dimos para lograrlo. Básicamente, el conjunto de datos que alimentamos como el entrenamiento contiene una simplificación numérica de las imágenes que representan señales viales. Veamos cómo se obtuvieron.

Cada fotografía de señales viales fue dividida en una rejilla de 4x4, dando 16 partes representadas por cuadrados. Enseguida se extrajo el color del píxel central de cada uno de estos cuadros. El color fue cuantificado considerando el nivel RGB, es decir, la cantidad de rojo, verde y azul de dicho píxel. Recordemos que los valores RGB van desde 0 hasta 255. Así se obtuvo el conjunto de entrenamiento, con hasta 48 valores representando cada fotografía de señales viales.

Exploremos el set de datos. Primero el panorama general algo resumido con `str()`:

```{r}
str(signs)
```

Supongamos que deseamos saber cuántas señales de cada tipo están contenidas en nuestros datos. Eso se consigue con la función `table()` con la columna de los tipos de señal como argumento (no olvidemos que es la primera columna).

```{r}
table(signs[, 1])
```

Es posible revisar los niveles promedio de color de alguna columna específica con el comando `aggregate()`. Calculemos el promedio de color del décimo cuadro pero clasificado por tipo de señal:

```{r}
aggregate(r10 ~ sign_type, data = signs, mean)
```

Desglosemos esta función. El primer argumento es la forma de organizar los datos, la columna r10 con respecto a la que que contiene los nombres del tipo de señal; enseguida escribimos el nombre del conjunto de datos y al final cuál medida estadística deseamos calcular.

### Clasificando un conjunto de señales viales {#clasificando-un-conjunto-de-señales-viales}

Ahora realizaremos una prueba de manejo que incluye 59 señales adicionales divididas en tres categorías: alto, límite de velocidad y paso peatonal. Al final de la prueba, debemos medir el nivel de éxito del coche en reconocer dichas señales. Seguiremos trabajando con nuestro conjunto de datos con la adición de los datos de prueba, llamados `test_signs`.

```{r}
test_signs <- read.csv("Datasets/test_signs.csv")
```

Clasifiquemos los datos de las señales de prueba con `knn()` y asignemos el resultado a una variable.

-   `train` volverá a ser nuestros datos de entrenamiento sin etiquetas.

-   `test` se refiere ahora a los datos de prueba `test_signs`, también sin etiquetas.

-   `cl` vuelve a ser el vector de etiquetas creado anteriormente.

```{r}
sign_types <- signs$sign_type
signs_pred <- knn(train = signs[, -1], test = test_signs[, -1], cl = sign_types)
signs_pred
```

R nos devuelve el conjunto de sus lecturas en cuanto a las señales viales que encontró en la prueba. Toca verificar qué tan preciso resultó ser nuestro modelo con respecto a las señales reales. Para ello, primero crearemos un vector con las etiquetas de las señales reales y después con la función `table()` crearemos una tabla cruzada o matriz de confusión que compare los valores pronosticados contra los reales:

```{r}
signs_actual <- test_signs$sign_type
signs_actual
table(signs_pred, signs_actual)
```

Calculemos la precisión de nuestro modelo:

```{r}
mean(signs_pred == signs_actual)
```

Resultó ser totalmente preciso, lo cual no es normal que ocurra siempre.

### Probando otros valores de k {#probando-otros-valores-de-k}

El valor de la constante *k* permite modificar el rendimiento de nuestros algoritmos. La *k* se refiere al número de vecinos a tomar en cuenta para la clasificación. Por ejemplo, si lo dejamos sin modificar, R dará un valor de *k = 1*, por lo que elegirá solo la imagen más cercana a la prueba. Si incrementamos el valor, se tomará en cuenta tantos vecinos como valga la *k* y eso podría redundar en una mayor exactitud del modelo al tener más elementos que considerar. Sin embargo, esto no siempre es lo mejor, ya que valores pequeños pueden detectar patrones más sutiles en nuestro modelo.

Probemos valores de *k* a 1, 7 y 25 para examinar su impacto en la exactitud del modelo de aprendizaje:

```{r}
k_1 <- knn(train = signs[, -1], test = test_signs[, -1], cl = sign_types)
mean(signs_actual == k_1)
```

Ahora probemos con 7 vecinos.

```{r}
k_7 <- knn(train = signs[, -1], test = test_signs[, -1], cl = sign_types, k = 7)
mean(signs_actual == k_7)
```

Y con 25:

```{r}
k_25 <- knn(train = signs[, -1], test = test_signs[, -1], cl = sign_types, k = 25)
mean(signs_actual == k_25)
```

### Viendo cómo los vecinos se votaron {#viendo-cómo-los-vecinos-se-votaron}

Cuando múltiples vecinos más cercanos obtienen un voto, puede ser útil en ocasiones examinar si los votos fueron unánimes o dispersos. Por ejemplo, saber más acerca de la seguridad con que se realizaron los votos podría permitirle a un vehículo autónomo tener precaución por si existe la posibilidad de toparse una señal de alto enfrente.

En este ejercicio veremos cómo obtener los resultados de la votación a partir de la función `knn()`.

Usaremos una *k = 7* y los datos ya conocidos, con la salvedad de agregar un argumento más, `prob = TRUE`. El resultado lo asignamos a una variable

```{r}
sign_pred2 <- knn(train = signs[, -1], test = test_signs[, -1], cl = sign_types, k = 7, prob = TRUE)
```

La función que nos permite obtener las proporciones de los votos es `attr()`, dándole como argumentos la variable obtenida antes y el atributo `"prob"`.

```{r}
sign_prob <- attr(sign_pred2, "prob")
```

Ahora examinemos los resultados de nuestra predicción y la proporción de votos para la clase ganadora:

```{r}
head(sign_pred2)
```

```{r}
head(sign_prob)
```
